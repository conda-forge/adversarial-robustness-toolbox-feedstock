{% set name = "adversarial-robustness-toolbox" %}
{% set version = "1.19.0" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/adversarial-robustness-toolbox-{{ version }}.tar.gz
  sha256: 28ac14b419afc9f85032d603eafc772802565002eea21d34f2474ae12f70a949

build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python >=3.9
    - setuptools
  run:
    - numpy >=1.18.0
    - python >=3.9    
    - scikit-learn >=0.22.2
    - scipy >=1.4.1
    - setuptools
    - six
    - tqdm

test:
  imports:
    - art
    - art.attacks
  commands:
    - pip check
  requires:
    - matplotlib-base
    - numba >=0.53.1
    - pillow
    - pip

about:
  home: https://github.com/Trusted-AI/adversarial-robustness-toolbox
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: Toolbox for adversarial machine learning.
  doc_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Documentation
  dev_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox

extra:
  recipe-maintainers:
    - jxn11
    - lockwoodar
    - mxr-conda
