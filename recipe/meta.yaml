{% set name = "adversarial-robustness-toolbox" %}
{% set version = "1.19.2" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/{{ name | replace('-', '_') }}-{{ version }}.tar.gz
  sha256: 6edf27e704d395aa592403d243991aa69b518ec2c5aec0c63292a490df7628f5

build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python {{ python_min }}
    - setuptools
  run:
    - numpy >=1.18.0
    - python >={{ python_min }}
    - scikit-learn >=0.22.2
    - scipy >=1.4.1
    - setuptools
    - six
    - tqdm

test:
  imports:
    - art
    - art.attacks
  commands:
    - pip check
  requires:
    - matplotlib-base
    - numba >=0.53.1
    - pillow
    - pip
    - python {{ python_min }}

about:
  home: https://github.com/Trusted-AI/adversarial-robustness-toolbox
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: Toolbox for adversarial machine learning.
  doc_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Documentation
  dev_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox

extra:
  recipe-maintainers:
    - jxn11
    - lockwoodar
    - mxr-conda
